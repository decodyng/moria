{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "# import utils2; importlib.reload(utils2)\n",
    "# from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def res_block(inp, kernel_size): \n",
    "    num_outputs = inp.get_shape()[-1].value\n",
    "    h1 = Convolution2D(nb_filter=num_outputs, nb_row=kernel_size, nb_col=kernel_size, \n",
    "                      subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 220, 220, 32)\n",
      "(?, 110, 110, 64)\n",
      "(?, 55, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(220, 220, 3))\n",
    "#TODO: Mirror padding instead of zero-padding; use old module for that \n",
    "x = Convolution2D(nb_filter=32, nb_row=9, nb_col=9, subsample=(1, 1), border_mode='same')(x)\n",
    "print(x.get_shape())\n",
    "x = Convolution2D(nb_filter=64, nb_row=3, nb_col=3, subsample=(2, 2), border_mode='same')(x)\n",
    "print(x.get_shape())\n",
    "x = Convolution2D(nb_filter=128, nb_row=3, nb_col=3, subsample=(2, 2), border_mode='same')(x)\n",
    "print(x.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Start with an image of size 220 by 220, with 3 channels, each of which contains color information. \n",
    "Then, create a convolutional layer with 32 9x9 filters, with a stride of 1 in each direction, and a border mode of 'same', meaning that every pixel in the input volume has a convolution for which it is the center of the convolution (modulo changes for subsampling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.Variable([1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "style_labels = tf.constant([[0, 1], [6, 7], [9, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [6, 7],\n",
       "       [9, 5]], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_labels.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "style_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.nn.batch_normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_6:0' shape=(2, 1, 1, 3) dtype=int32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.expand_dims(foo, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shape = tf.TensorShape([4]).concatenate(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(6)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "beta = slim.model_variable('beta2',\n",
    "                                shape=shape,\n",
    "                                dtype='float64',\n",
    "                                initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "style_labels = tf.constant([0, 0, 3, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(beta, style_labels).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shape = tf.TensorShape([num_categories]).concatenate(params_shape)\n",
    "var_collections = slim.utils.get_variable_collections(\n",
    "  variables_collections, name)\n",
    "var = slim.model_variable(name,\n",
    "                        shape=shape,\n",
    "                        dtype=dtype,\n",
    "                        initializer=initializer,\n",
    "                        collections=var_collections,\n",
    "                        trainable=trainable)\n",
    "conditioned_var = tf.gather(var, labels)\n",
    "conditioned_var = tf.expand_dims(tf.expand_dims(conditioned_var, 1), 1)\n",
    "return conditioned_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = merge([inp for i in range(10)], mode='concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(10, 3) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.reshape(x, shape=(10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Conditional Instance Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import pdb\n",
    "import keras\n",
    "from keras.engine.topology import to_list\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializations, regularizers\n",
    "from keras import backend as K \n",
    "from keras.layers import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ConditionalInstanceNormalization(Layer):\n",
    "    \"\"\"Builds upon (i.e. borrows liberally from) the existing Batch\n",
    "    Normalization layer within Keras, but then implements Conditional Instance Normalization\n",
    "    as described here: https://arxiv.org/pdf/1610.07629.pdf\n",
    "    # Arguments\n",
    "        num_categories: The number of categories upon which you're conditionally normalizing.\n",
    "                        If using for style transfer, this corresponds to the\n",
    "                        number of distinct styles. Set to 2 by default.\n",
    "\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "\n",
    "        momentum: Momentum for the moving average.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        moving_mean_initializer: Initializer for the moving mean.\n",
    "        moving_variance_initializer: Initializer for the moving variance.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "TODO\n",
    "\"\"\"\n",
    "    def __init__(self, num_categories=2, epsilon=1e-3, mode=0, axis=-1, momentum=0.99,\n",
    "                 weights=None, beta_init='zero', gamma_init='one',\n",
    "                 gamma_regularizer=None, beta_regularizer=None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.num_categories=2\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.epsilon = epsilon\n",
    "        self.mode = mode\n",
    "        self.axis = axis\n",
    "        self.momentum = momentum\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.initial_weights = weights\n",
    "        if self.mode == 0:\n",
    "            self.uses_learning_phase = True\n",
    "        super(ConditionalInstanceNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        feature_dim = input_shape[0][self.axis]\n",
    "        row_shape = (feature_dim,)\n",
    "        shape = (self.num_categories, feature_dim)\n",
    "\n",
    "        self.gamma = K.reshape(merge([self.add_weight(row_shape,\n",
    "                                             name='gamma',\n",
    "                                             initializer=self.gamma_init,\n",
    "                                             regularizer=self.gamma_regularizer) for i in range(self.num_categories)],\n",
    "                                   mode='concat'), shape=shape)\n",
    "\n",
    "        self.beta = K.reshape(merge([self.add_weight(row_shape,\n",
    "                                             name='beta',\n",
    "                                             initializer=self.beta_init,\n",
    "                                             regularizer=self.beta_regularizer) for i in range(self.num_categories)],\n",
    "                                   mode='concat'), shape=shape)\n",
    "\n",
    "        self.running_mean = self.add_weight(row_shape, initializer='zero',\n",
    "                                                name='{}_running_mean'.format(self.name),\n",
    "                                                trainable=False)\n",
    "\n",
    "        self.running_std = self.add_weight(row_shape, initializer='one',\n",
    "                                           name='{}_running_std'.format(self.name),\n",
    "                                           trainable=False)\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "#     def __call__(self, x, mask=None):\n",
    "#             '''Wrapper around self.call(), for handling\n",
    "#             internal Keras references.\n",
    "\n",
    "#             If a Keras tensor is passed:\n",
    "#                 - We call self.add_inbound_node().\n",
    "#                 - If necessary, we `build` the layer to match\n",
    "#                     the _keras_shape of the input(s).\n",
    "#                 - We update the _keras_shape of every input tensor with\n",
    "#                     its new shape (obtained via self.get_output_shape_for).\n",
    "#                     This is done as part of add_inbound_node().\n",
    "#                 - We update the _keras_history of the output tensor(s)\n",
    "#                     with the current layer.\n",
    "#                     This is done as part of add_inbound_node().\n",
    "\n",
    "#             # Arguments\n",
    "#                 x: Can be a tensor or list/tuple of tensors.\n",
    "#                 mask: Tensor or list/tuple of tensors.\n",
    "#             '''\n",
    "#             pdb.set_trace()\n",
    "#             if not self.built:\n",
    "#                 # Raise exceptions in case the input is not compatible\n",
    "#                 # with the input_spec specified in the layer constructor.\n",
    "#                 self.assert_input_compatibility(x)\n",
    "\n",
    "#                 # Collect input shapes to build layer.\n",
    "#                 input_shapes = []\n",
    "#                 for x_elem in x:\n",
    "#                     if hasattr(x_elem, '_keras_shape'):\n",
    "#                         input_shapes.append(x_elem._keras_shape)\n",
    "#                     elif hasattr(K, 'int_shape'):\n",
    "#                         input_shapes.append(K.int_shape(x_elem))\n",
    "#                     else:\n",
    "#                         raise ValueError('You tried to call layer \"' + self.name +\n",
    "#                                          '\". This layer has no information'\n",
    "#                                          ' about its expected input shape, '\n",
    "#                                          'and thus cannot be built. '\n",
    "#                                          'You can build it manually via: '\n",
    "#                                          '`layer.build(batch_input_shape)`')\n",
    "#                 if len(input_shapes) == 1:\n",
    "#                     self.build(input_shapes[0])\n",
    "#                 else:\n",
    "#                     self.build(input_shapes)\n",
    "#                 self.built = True\n",
    "\n",
    "#             # Raise exceptions in case the input is not compatible\n",
    "#             # with the input_spec set at build time.\n",
    "\n",
    "#             self.assert_input_compatibility(x)\n",
    "\n",
    "#             input_tensors = x\n",
    "#             inbound_layers = []\n",
    "#             node_indices = []\n",
    "#             tensor_indices = []\n",
    "#             for input_tensor in input_tensors:\n",
    "#                 if hasattr(input_tensor, '_keras_history') and input_tensor._keras_history:\n",
    "#                     # This is a Keras tensor.\n",
    "#                     previous_layer, node_index, tensor_index = input_tensor._keras_history\n",
    "#                     inbound_layers.append(previous_layer)\n",
    "#                     node_indices.append(node_index)\n",
    "#                     tensor_indices.append(tensor_index)\n",
    "#                 else:\n",
    "#                     inbound_layers = None\n",
    "#                     break\n",
    "\n",
    "#             if inbound_layers:\n",
    "#                 # This will call layer.build() if necessary.\n",
    "#                 self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n",
    "#                 # Outputs were already computed when calling self.add_inbound_node.\n",
    "#                 outputs = self.inbound_nodes[-1].output_tensors\n",
    "#                 # If single output tensor: return it,\n",
    "#                 # else return a list (at least 2 elements).\n",
    "#                 if len(outputs) == 1:\n",
    "#                     return outputs[0]\n",
    "#                 else:\n",
    "#                     return outputs\n",
    "#             else:\n",
    "#                 # This case appears if the input was not a Keras tensor.\n",
    "#                 return self.call(x, mask)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        activations = x[0]\n",
    "        labels = x[1]\n",
    "        batch_gamma = K.gather(self.gamma, labels)\n",
    "        batch_beta = K.gather(self.beta, labels)\n",
    "\n",
    "        if self.mode == 0 or self.mode == 2:\n",
    "            assert self.built, 'Layer must be built before being called'\n",
    "\n",
    "            #so, in practice, I think we can keep a lot of this and\n",
    "            # just call it on inputs[0], keeping inputs[1] as a way to lookup\n",
    "            input_shape = K.int_shape(activations)\n",
    "\n",
    "            reduction_axes = list(range(len(input_shape)))\n",
    "            del reduction_axes[self.axis]\n",
    "            broadcast_shape = [1] * len(input_shape)\n",
    "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "            x_normed, mean, std = K.normalize_batch_in_training(\n",
    "                activations, batch_gamma, batch_beta, reduction_axes,\n",
    "                epsilon=self.epsilon)\n",
    "\n",
    "            if self.mode == 0:\n",
    "                self.add_update([K.moving_average_update(self.running_mean, mean, self.momentum),\n",
    "                                 K.moving_average_update(self.running_std, std, self.momentum)], activations)\n",
    "\n",
    "                if sorted(reduction_axes) == range(K.ndim(activations))[:-1]:\n",
    "                    x_normed_running = K.batch_normalization(\n",
    "                        activations, self.running_mean, self.running_std,\n",
    "                    batch_beta, batch_gamma,\n",
    "                        epsilon=self.epsilon)\n",
    "                else:\n",
    "                    # need broadcasting\n",
    "                    broadcast_running_mean = K.reshape(self.running_mean, broadcast_shape)\n",
    "                    broadcast_running_std = K.reshape(self.running_std, broadcast_shape)\n",
    "                    broadcast_beta = K.reshape(batch_beta, broadcast_shape)\n",
    "                    broadcast_gamma = K.reshape(batch_gamma, broadcast_shape)\n",
    "                    x_normed_running = K.batch_normalization(\n",
    "                        activations, broadcast_running_mean, broadcast_running_std,\n",
    "                        broadcast_beta, broadcast_gamma,\n",
    "                        epsilon=self.epsilon)\n",
    "\n",
    "                # pick the normalized form of x corresponding to the training phase\n",
    "                x_normed = K.in_train_phase(x_normed, x_normed_running)\n",
    "\n",
    "        elif self.mode == 1:\n",
    "\n",
    "            # sample-wise normalization\n",
    "            m = K.mean(activations, axis=-1, keepdims=True)\n",
    "            std = K.sqrt(K.var(activations, axis=-1, keepdims=True) + self.epsilon)\n",
    "            x_normed = (activations - m) / (std + self.epsilon)\n",
    "            x_normed =  batch_gamma * x_normed + batch_beta\n",
    "        return x_normed\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape): \n",
    "        return input_shape[0]\n",
    "    \n",
    "    def compute_mask(self, inp, input_masks): \n",
    "        return input_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 220, 220, 3)\n",
      "(?, 220, 220, 32)\n",
      "> <ipython-input-37-7cfda799942d>(172)call()\n",
      "-> activations = x[0]\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-597ca2018afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConditionalInstanceNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_categories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-7cfda799942d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mbatch_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-7cfda799942d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mbatch_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = Input(shape=(1,), dtype='int32')\n",
    "inp = Input(shape=(220, 220, 3))\n",
    "#TODO: Mirror padding instead of zero-padding; use old module for that \n",
    "print(inp.get_shape())\n",
    "x = Convolution2D(nb_filter=32, nb_row=9, nb_col=9, border_mode='same')(inp)\n",
    "print(x.get_shape())\n",
    "x = ConditionalInstanceNormalization(num_categories=2)([x, labels])\n",
    "print(x.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mod = Model([inp, labels], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(mod, to_file='model_5_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '../downloads/train/n04487081/*.JPEG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = glob(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image as pil_Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '../downloads/train/n04487081/*.JPEG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=pil_Image.open(test_files[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rn_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "preproc = lambda x: (x - rn_mean)[:, :, :, ::-1]\n",
    "def img_to_numpy(ig): \n",
    "    return np.expand_dims(np.array(ig), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_hr = bcolz.open('../downloads/trn_resized_288.bc')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAD/CAYAAAADiUt0AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nICIiIiJyJv8HapaJ8WgG+vgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('model_5_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19439"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [1]*5000 + [0]*5000 + [2]*5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
