{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce2e1e594e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils2\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils2'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def res_block(inp, kernel_size): \n",
    "    num_outputs = inp.get_shape()[-1].value\n",
    "    h1 = Convolution2D(nb_filter=num_outputs, nb_row=kernel_size, nb_col=kernel_size, \n",
    "                      subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(220, 220, 3))\n",
    "#TODO: Mirror padding instead of zero-padding; use old module for that \n",
    "x = Convolution2D(nb_filter=32, nb_row=9, nb_col=9, subsample=1, border_mode='same')(x)\n",
    "x = Convolution2D(nb_filter=64, nb_row=3, nb_col=3, subsample=2, border_mode='same')(x)\n",
    "x = Convolution2D(nb_filter=128, nb_row=3, nb_col=3, subsample=2, border_mode='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_shape()[-1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: function to do conditional normalization. I think here it's just as simple as passing in a\n",
    "#an additional parameter when your'e training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.Variable([1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style_labels = tf.constant([[0, 1], [6, 7], [9, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [6, 7],\n",
       "       [9, 5]], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_labels.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.batch_normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_6:0' shape=(2, 1, 1, 3) dtype=int32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.expand_dims(foo, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = tf.TensorShape([4]).concatenate(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(6)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = slim.model_variable('beta2',\n",
    "                                shape=shape,\n",
    "                                dtype='float64',\n",
    "                                initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_labels = tf.constant([0, 0, 3, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(beta, style_labels).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = tf.TensorShape([num_categories]).concatenate(params_shape)\n",
    "var_collections = slim.utils.get_variable_collections(\n",
    "  variables_collections, name)\n",
    "var = slim.model_variable(name,\n",
    "                        shape=shape,\n",
    "                        dtype=dtype,\n",
    "                        initializer=initializer,\n",
    "                        collections=var_collections,\n",
    "                        trainable=trainable)\n",
    "conditioned_var = tf.gather(var, labels)\n",
    "conditioned_var = tf.expand_dims(tf.expand_dims(conditioned_var, 1), 1)\n",
    "return conditioned_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = merge([inp for i in range(10)], mode='concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(10, 3) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.reshape(x, shape=(10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Instance Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConditionalInstanceNormalization(Layer):\n",
    "    \"\"\"Builds upon (i.e. borrows liberally from) the existing Batch\n",
    "    Normalization layer within Keras, but then implements Conditional Instance Normalization\n",
    "    as described here: https://arxiv.org/pdf/1610.07629.pdf\n",
    "    # Arguments\n",
    "        num_categories: The number of categories upon which you're conditionally normalizing.\n",
    "                        If using for style transfer, this corresponds to the\n",
    "                        number of distinct styles. Set to 2 by default.\n",
    "\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "\n",
    "        momentum: Momentum for the moving average.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        moving_mean_initializer: Initializer for the moving mean.\n",
    "        moving_variance_initializer: Initializer for the moving variance.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "TODO\n",
    "\"\"\"\n",
    "    def __init__(self, num_categories=2, epsilon=1e-3, mode=0, axis=-1, momentum=0.99,\n",
    "                 weights=None, beta_init='zero', gamma_init='one',\n",
    "                 gamma_regularizer=None, beta_regularizer=None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.num_categories=2\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.epsilon = epsilon\n",
    "        self.mode = mode\n",
    "        self.axis = axis\n",
    "        self.momentum = momentum\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.initial_weights = weights\n",
    "        if self.mode == 0:\n",
    "            self.uses_learning_phase = True\n",
    "        super(ConditionalInstanceNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        feature_dim = input_shape[0][self.axis]\n",
    "        row_shape = (feature_dim,)\n",
    "        shape = (self.num_categories, feature_dim)\n",
    "\n",
    "        self.gamma = K.reshape(merge([self.add_weight(row_shape,\n",
    "                                             name='gamma',\n",
    "                                             initializer=self.gamma_init,\n",
    "                                             regularizer=self.gamma_regularizer) for i in range(self.num_categories)],\n",
    "                                   mode='concat'), shape=shape)\n",
    "\n",
    "        self.beta = K.reshape(merge([self.add_weight(row_shape,\n",
    "                                             name='beta',\n",
    "                                             initializer=self.beta_init,\n",
    "                                             regularizer=self.beta_regularizer) for i in range(self.num_categories)],\n",
    "                                   mode='concat'), shape=shape)\n",
    "\n",
    "        self.running_mean = self.add_weight(row_shape, initializer='zero',\n",
    "                                                name='{}_running_mean'.format(self.name),\n",
    "                                                trainable=False)\n",
    "\n",
    "        self.running_std = self.add_weight(row_shape, initializer='one',\n",
    "                                           name='{}_running_std'.format(self.name),\n",
    "                                           trainable=False)\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "            '''Wrapper around self.call(), for handling\n",
    "            internal Keras references.\n",
    "\n",
    "            If a Keras tensor is passed:\n",
    "                - We call self.add_inbound_node().\n",
    "                - If necessary, we `build` the layer to match\n",
    "                    the _keras_shape of the input(s).\n",
    "                - We update the _keras_shape of every input tensor with\n",
    "                    its new shape (obtained via self.get_output_shape_for).\n",
    "                    This is done as part of add_inbound_node().\n",
    "                - We update the _keras_history of the output tensor(s)\n",
    "                    with the current layer.\n",
    "                    This is done as part of add_inbound_node().\n",
    "\n",
    "            # Arguments\n",
    "                x: Can be a tensor or list/tuple of tensors.\n",
    "                mask: Tensor or list/tuple of tensors.\n",
    "            '''\n",
    "            if not self.built:\n",
    "                # Raise exceptions in case the input is not compatible\n",
    "                # with the input_spec specified in the layer constructor.\n",
    "                self.assert_input_compatibility(x)\n",
    "\n",
    "                # Collect input shapes to build layer.\n",
    "                input_shapes = []\n",
    "                for x_elem in x:\n",
    "                    if hasattr(x_elem, '_keras_shape'):\n",
    "                        input_shapes.append(x_elem._keras_shape)\n",
    "                    elif hasattr(K, 'int_shape'):\n",
    "                        input_shapes.append(K.int_shape(x_elem))\n",
    "                    else:\n",
    "                        raise ValueError('You tried to call layer \"' + self.name +\n",
    "                                         '\". This layer has no information'\n",
    "                                         ' about its expected input shape, '\n",
    "                                         'and thus cannot be built. '\n",
    "                                         'You can build it manually via: '\n",
    "                                         '`layer.build(batch_input_shape)`')\n",
    "                if len(input_shapes) == 1:\n",
    "                    self.build(input_shapes[0])\n",
    "                else:\n",
    "                    self.build(input_shapes)\n",
    "                self.built = True\n",
    "\n",
    "            # Raise exceptions in case the input is not compatible\n",
    "            # with the input_spec set at build time.\n",
    "\n",
    "            self.assert_input_compatibility(x)\n",
    "\n",
    "            input_tensors = x\n",
    "            inbound_layers = []\n",
    "            node_indices = []\n",
    "            tensor_indices = []\n",
    "            for input_tensor in input_tensors:\n",
    "                if hasattr(input_tensor, '_keras_history') and input_tensor._keras_history:\n",
    "                    # This is a Keras tensor.\n",
    "                    previous_layer, node_index, tensor_index = input_tensor._keras_history\n",
    "                    inbound_layers.append(previous_layer)\n",
    "                    node_indices.append(node_index)\n",
    "                    tensor_indices.append(tensor_index)\n",
    "                else:\n",
    "                    inbound_layers = None\n",
    "                    break\n",
    "\n",
    "            if inbound_layers:\n",
    "                # This will call layer.build() if necessary.\n",
    "                self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n",
    "                # Outputs were already computed when calling self.add_inbound_node.\n",
    "                outputs = self.inbound_nodes[-1].output_tensors\n",
    "                # If single output tensor: return it,\n",
    "                # else return a list (at least 2 elements).\n",
    "                if len(outputs) == 1:\n",
    "                    return outputs[0]\n",
    "                else:\n",
    "                    return outputs\n",
    "            else:\n",
    "                # This case appears if the input was not a Keras tensor.\n",
    "                return self.call(x, mask)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        activations = x[0]\n",
    "        labels = x[1]\n",
    "        batch_gamma = K.gather(self.gamma, labels)\n",
    "        batch_beta = K.gather(self.beta, labels)\n",
    "\n",
    "        if self.mode == 0 or self.mode == 2:\n",
    "            assert self.built, 'Layer must be built before being called'\n",
    "\n",
    "            #so, in practice, I think we can keep a lot of this and\n",
    "            # just call it on inputs[0], keeping inputs[1] as a way to lookup\n",
    "            input_shape = K.int_shape(activations)\n",
    "\n",
    "            reduction_axes = list(range(len(input_shape)))\n",
    "            del reduction_axes[self.axis]\n",
    "            broadcast_shape = [1] * len(input_shape)\n",
    "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "            x_normed, mean, std = K.normalize_batch_in_training(\n",
    "                activations, batch_gamma, batch_beta, reduction_axes,\n",
    "                epsilon=self.epsilon)\n",
    "\n",
    "            if self.mode == 0:\n",
    "                self.add_update([K.moving_average_update(self.running_mean, mean, self.momentum),\n",
    "                                 K.moving_average_update(self.running_std, std, self.momentum)], activations)\n",
    "\n",
    "                if sorted(reduction_axes) == range(K.ndim(activations))[:-1]:\n",
    "                    x_normed_running = K.batch_normalization(\n",
    "                        activations, self.running_mean, self.running_std,\n",
    "                    batch_beta, batch_gamma,\n",
    "                        epsilon=self.epsilon)\n",
    "                else:\n",
    "                    # need broadcasting\n",
    "                    broadcast_running_mean = K.reshape(self.running_mean, broadcast_shape)\n",
    "                    broadcast_running_std = K.reshape(self.running_std, broadcast_shape)\n",
    "                    broadcast_beta = K.reshape(batch_beta, broadcast_shape)\n",
    "                    broadcast_gamma = K.reshape(batch_gamma, broadcast_shape)\n",
    "                    x_normed_running = K.batch_normalization(\n",
    "                        activations, broadcast_running_mean, broadcast_running_std,\n",
    "                        broadcast_beta, broadcast_gamma,\n",
    "                        epsilon=self.epsilon)\n",
    "\n",
    "                # pick the normalized form of x corresponding to the training phase\n",
    "                x_normed = K.in_train_phase(x_normed, x_normed_running)\n",
    "\n",
    "        elif self.mode == 1:\n",
    "\n",
    "            # sample-wise normalization\n",
    "            m = K.mean(activations, axis=-1, keepdims=True)\n",
    "            std = K.sqrt(K.var(activations, axis=-1, keepdims=True) + self.epsilon)\n",
    "            x_normed = (activations - m) / (std + self.epsilon)\n",
    "            x_normed =  batch_gamma * x_normed + batch_beta\n",
    "        return x_normed\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape): \n",
    "        return input_shape[0]\n",
    "    \n",
    "    def compute_mask(self, input, input_mask=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = Input(shape=(1,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `compute_mask` method of layer \"conditionalinstancenormalization_21\" should return one mask tensor per output tensor of the layer. Found: [None, None]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-24d355de2050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#TODO: Mirror padding instead of zero-padding; use old module for that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConditionalInstanceNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_categories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#x = ConditionalInstanceNormalization(num_categories=2)([x, labels])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-ca6801510b88>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    190\u001b[0m                              \u001b[0;34m'\" should return one mask tensor per '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                              \u001b[0;34m'output tensor of the layer. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                              str(output_masks))\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `compute_mask` method of layer \"conditionalinstancenormalization_21\" should return one mask tensor per output tensor of the layer. Found: [None, None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m(192)\u001b[0;36mcreate_node\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    190 \u001b[0;31m                             \u001b[0;34m'\" should return one mask tensor per '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m                             \u001b[0;34m'output tensor of the layer. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 192 \u001b[0;31m                             str(output_masks))\n",
      "\u001b[0m\u001b[0;32m    193 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    194 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> output_masks\n",
      "[None, None]\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(220, 220, 3))\n",
    "#TODO: Mirror padding instead of zero-padding; use old module for that \n",
    "x = Convolution2D(nb_filter=32, nb_row=9, nb_col=9, border_mode='same')(x)\n",
    "x = ConditionalInstanceNormalization(num_categories=2)([x, labels])\n",
    "\n",
    "#x = ConditionalInstanceNormalization(num_categories=2)([x, labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
